{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import numpy as np\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_epa</th>\n",
       "      <th>total_first_downs</th>\n",
       "      <th>target_share</th>\n",
       "      <th>redzone</th>\n",
       "      <th>offense_pct</th>\n",
       "      <th>total_usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.258469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.303061</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.905386</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.298625</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.561272</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_epa  total_first_downs  target_share  redzone  offense_pct  \\\n",
       "1  -0.258469                0.0      0.111111      0.0         0.66   \n",
       "2   0.303061                1.0      0.090909      0.0         0.66   \n",
       "3   0.905386                1.0      0.060000      0.0         0.40   \n",
       "6   0.298625                3.0      0.325581      2.0         1.00   \n",
       "7   2.561272                1.0      0.236842      1.0         1.00   \n",
       "\n",
       "   total_usage  \n",
       "1            4  \n",
       "2            3  \n",
       "3            3  \n",
       "6           14  \n",
       "7            9  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure SQL\n",
    "\n",
    "def execute_statement(sql: str):\n",
    "    with psycopg2.connect(host=\"localhost\", database=\"thefantasybot\", user=\"tbakely\") as conn:\n",
    "         df = pd.read_sql(sql, conn)\n",
    "         return df\n",
    "\n",
    "weekly_sql = \"\"\"\n",
    "select\n",
    "\twd.player_id,\n",
    "\twd.player_name,\n",
    "\tposition,\n",
    "\trecent_team,\n",
    "\twd.season,\n",
    "\twd.week,\n",
    "\tcarries,\n",
    "\trushing_yards,\n",
    "\trushing_tds,\n",
    "\trushing_fumbles,\n",
    "\trushing_fumbles_lost,\n",
    "\trushing_first_downs,\n",
    "\trushing_epa,\n",
    "\t--efficiency,\n",
    "\t--percent_attempts_gte_eight_defenders,\n",
    "\t--avg_time_to_los,\n",
    "\t--rush_yards_over_expected,\n",
    "\t--avg_rush_yards,\n",
    "\t--rush_yards_over_expected_per_att,\n",
    "\t--rush_pct_over_expected,\n",
    "\twd.receptions,\n",
    "\twd.targets,\n",
    "\treceiving_yards,\n",
    "\treceiving_tds,\n",
    "\treceiving_fumbles,\n",
    "\treceiving_fumbles_lost,\n",
    "\treceiving_air_yards,\n",
    "\treceiving_yards_after_catch,\n",
    "\treceiving_first_downs,\n",
    "\treceiving_epa,\n",
    "\tracr,\n",
    "\ttarget_share,\n",
    "\tair_yards_share,\n",
    "\twopr,\n",
    "\toffense_snaps,\n",
    "\toffense_pct,\n",
    "    redzone.redzone,\n",
    "\t(carries + wd.targets) as total_usage,\n",
    "    wd.fantasy_points,\n",
    "    wd.fantasy_points_ppr,\n",
    "\troof,\n",
    "\tsurface,\n",
    "\tweather_hazards,\n",
    "\ttemp,\n",
    "\thumidity,\n",
    "\twind_speed\n",
    "from archive_data.weekly_data wd\n",
    "left join archive_data.offense_snap_counts os\n",
    "on wd.player_id = os.id\n",
    "and wd.season = os.season\n",
    "and wd.week = os.week\n",
    "left join archive_data.ngs_rushing_data ngsr\n",
    "on wd.player_id = ngsr.player_gsis_id\n",
    "and wd.season = ngsr.season\n",
    "and wd.week = ngsr.week\n",
    "left join archive_data.ngs_receiving_data ngsrr\n",
    "on wd.player_id = ngsrr.player_gsis_id\n",
    "and wd.season = ngsrr.season\n",
    "and wd.week = ngsrr.week\n",
    "left join (select distinct rusher_player_id, game_id, season, week from archive_data.full_pbp) game_id\n",
    "on wd.player_id = game_id.rusher_player_id\n",
    "and wd.season = game_id.season\n",
    "and wd.week = game_id.week\n",
    "left join archive_data.game_data\n",
    "on game_data.game_id = game_id.game_id\n",
    "left join archive_data.redzone_snaps redzone\n",
    "on wd.player_id = redzone.player_id\n",
    "and wd.season = redzone.season\n",
    "and wd.week = redzone.week\n",
    "where position in ('WR', 'RB', 'TE')\n",
    "and wd.season between 2016 and 2022;\n",
    "\"\"\"\n",
    "\n",
    "# Load weekly data from 2016-2022; Modify above query as needed\n",
    "weekly = execute_statement(weekly_sql)\n",
    "\n",
    "# Dealing with null values\n",
    "weekly1 = weekly.copy()\n",
    "weekly1.dropna(subset=[\"player_name\"], inplace=True)\n",
    "weekly1.dropna(subset=[\"offense_snaps\"], inplace=True)\n",
    "\n",
    "fill_na_cols = [\n",
    "    \"rushing_epa\",\n",
    "    \"receiving_epa\",\n",
    "    \"racr\",\n",
    "    \"target_share\",\n",
    "    \"air_yards_share\",\n",
    "    \"wopr\",\n",
    "    \"redzone\",\n",
    "]\n",
    "\n",
    "weather_cols = [\n",
    "    \"roof\",\n",
    "    \"surface\",\n",
    "    \"weather_hazards\",\n",
    "    \"temp\",\n",
    "    \"humidity\",\n",
    "    \"wind_speed\",\n",
    "]\n",
    "\n",
    "for col in fill_na_cols:\n",
    "    weekly1[col] = weekly[col].fillna(0)\n",
    "\n",
    "weekly1 = weekly1[[col for col in weekly1.columns if col not in weather_cols]]\n",
    "weekly1[\"week\"] = weekly1[\"week\"].astype(str)\n",
    "weekly1[\"season\"] = weekly1[\"season\"].astype(str)\n",
    "\n",
    "weekly1[\"scored\"] = np.where((weekly1[\"receiving_tds\"] > 0) | (weekly1[\"rushing_tds\"] > 0), 1, 0)\n",
    "weekly1[\"multi_score\"] = np.where(weekly1[\"receiving_tds\"] + weekly1[\"rushing_tds\"] > 1, 1, 0)\n",
    "weekly1[\"total_yards\"] = weekly1[\"rushing_yards\"] + weekly1[\"receiving_yards\"]\n",
    "weekly1[\"total_epa\"] = weekly1[\"rushing_epa\"] + weekly1[\"receiving_epa\"]\n",
    "weekly1[\"total_first_downs\"] = weekly1[\"rushing_first_downs\"] + weekly1[\"receiving_first_downs\"]\n",
    "\n",
    "\n",
    "try_columns = [\"total_epa\", \"total_first_downs\", \"target_share\", \"redzone\", \"offense_pct\", \"total_usage\"]\n",
    "\n",
    "\n",
    "model_data = weekly1[try_columns]\n",
    "model_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Model set up\n",
    "X = model_data.values\n",
    "y = weekly1[[\"fantasy_points_ppr\"]].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Imports\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"fivethirtyeight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting data_preparation/v0.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile data_preparation/v0.py\n",
    "\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train).float().to(device)\n",
    "y_train_tensor = torch.tensor(y_train).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i data_preparation/v0.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_configuration/v0.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_configuration/v0.py\n",
    "\n",
    "# Set device\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set learning rate\n",
    "lr = 0.001\n",
    "\n",
    "# Create model and send to device\n",
    "model = nn.Sequential(nn.Linear(6,1)).to(device)\n",
    "\n",
    "# Define an SGD optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# Define the MSE loss function\n",
    "loss_fn = nn.MSELoss(reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_configuration/v0.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_training/v0.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_training/v0.py\n",
    "\n",
    "# Define number of epochs\n",
    "n_epochs = 1000\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "\n",
    "    # Step 1 - Compute the output\n",
    "    yhat = model(X_train_tensor)\n",
    "\n",
    "    # Step 2 - Compute the loss\n",
    "    loss = loss_fn(yhat, y_train_tensor)\n",
    "\n",
    "    # Step 3 - Compute the gradients for b and w\n",
    "    loss.backward()\n",
    "\n",
    "    # Step 4 - Update parameters\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_training/v0.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[0.8105, 1.3459, 0.7200, 0.2973, 0.7444, 0.4834]])), ('0.bias', tensor([1.0452]))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper higher order function for training\n",
    "\n",
    "def make_train_step_fn(model, loss_fn, optimizer):\n",
    "    def perform_train_step_fn(X, y):\n",
    "        model.train()\n",
    "\n",
    "        # Step 1 - Compute the output\n",
    "        yhat = model(X)\n",
    "\n",
    "        # Step 2 - Compute the loss\n",
    "        loss = loss_fn(yhat, y)\n",
    "\n",
    "        # Step 3 - Compute the gradients for b and w\n",
    "        loss.backward()\n",
    "\n",
    "        # Step 4 - Update parameters\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Return the loss\n",
    "        return loss.item()\n",
    "    \n",
    "    return perform_train_step_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i data_preparation/v0.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model_configuration/v1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_configuration/v1.py\n",
    "\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set learning rate\n",
    "lr = 0.001\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Define model\n",
    "model = nn.Sequential(nn.Linear(6,1)).to(device)\n",
    "\n",
    "# Define SGD optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# Define the MSE loss function\n",
    "loss_fn = nn.MSELoss(reduction=\"mean\")\n",
    "\n",
    "# Create the train_step function for our model, loss, and optimizer\n",
    "train_step_fn = make_train_step_fn(model, loss_fn, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_configuration/v1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model_training/v1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_training/v1.py\n",
    "\n",
    "# Define number of epochs\n",
    "n_epochs = 1000\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    loss = train_step_fn(X_train_tensor, y_train_tensor)\n",
    "    losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_training/v1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[0.7875, 1.4565, 0.0289, 0.2645, 0.7500, 0.4758]])), ('0.bias', tensor([0.9314]))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What a custom class may look like\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x_tensor, y_tensor):\n",
    "        super().__init__()\n",
    "        self.x = x_tensor\n",
    "        self.y = y_tensor\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([-1.4441,  3.0000,  0.4400,  0.0000,  0.9400, 11.0000]), tensor([14.2000]))\n"
     ]
    }
   ],
   "source": [
    "x_train_tensor = torch.as_tensor(X_train).float()\n",
    "y_train_tensor = torch.as_tensor(y_train).float()\n",
    "\n",
    "train_data = CustomDataset(x_train_tensor, y_train_tensor)\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([-1.4441,  3.0000,  0.4400,  0.0000,  0.9400, 11.0000]), tensor([14.2000]))\n"
     ]
    }
   ],
   "source": [
    "# If we only have a couple of tensors, we can use TensorDataset\n",
    "\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now use PyTorch's DataLoader which we NEED to do batch gradient descent\n",
    "# ALWAYS set shuffle=True for the training set to avoid data leakage, unless\n",
    "# doing something like time series\n",
    "# No need to shuffle the test sets because we are NOT computing their gradients\n",
    "\n",
    "# Mini batch size: powers of 2 (e.g. 16, 32, 64, 128)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data_preparation/v1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile data_preparation/v1.py\n",
    "\n",
    "X_train_tensor = torch.as_tensor(X_train).float()\n",
    "y_train_tensor = torch.as_tensor(y_train).float()\n",
    "\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i data_preparation/v1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_configuration/v1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model_training/v2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_training/v2.py\n",
    "\n",
    "# Define epochs\n",
    "n_epochs = 1000\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # mini batch loop\n",
    "    mini_batch_losses = []\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        # Send each mini batch to device\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        mini_batch_loss = train_step_fn(x_batch, y_batch)\n",
    "        mini_batch_losses.append(mini_batch_loss)\n",
    "    \n",
    "    # average loss over all mini batches\n",
    "    loss = np.mean(mini_batch_losses)\n",
    "    losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_training/v2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13.282407255454258,\n",
       " 11.89312636896253,\n",
       " 11.658273424521584,\n",
       " 11.431098318363908,\n",
       " 11.347354696509584,\n",
       " 11.260353657416312,\n",
       " 11.150396601828263,\n",
       " 11.12010001062907,\n",
       " 11.028354788002492,\n",
       " 10.957173211196253,\n",
       " 10.913551287457512,\n",
       " 10.86627813810792,\n",
       " 10.85276506043888,\n",
       " 10.76486308460306,\n",
       " 10.769381363101552,\n",
       " 10.684876007259552,\n",
       " 10.64103591811613,\n",
       " 10.651003150306504,\n",
       " 10.570721113857747,\n",
       " 10.579957814058254,\n",
       " 10.52525898939569,\n",
       " 10.53196040132389,\n",
       " 10.480088996359344,\n",
       " 10.474971118272451,\n",
       " 10.437485200628583,\n",
       " 10.413304038505272,\n",
       " 10.369551836520543,\n",
       " 10.29810795212144,\n",
       " 10.296200768182198,\n",
       " 10.284556536480949,\n",
       " 10.24843507552059,\n",
       " 10.234301273585245,\n",
       " 10.21682956632213,\n",
       " 10.200826351493047,\n",
       " 10.17850613699628,\n",
       " 10.13094442902456,\n",
       " 10.14470091719469,\n",
       " 10.139005098395682,\n",
       " 10.096764054597523,\n",
       " 10.100055080322322,\n",
       " 10.050454282672643,\n",
       " 10.048748749472558,\n",
       " 10.011304151615974,\n",
       " 9.99980534653822,\n",
       " 9.965119869506667,\n",
       " 9.94447472772915,\n",
       " 9.951626711314015,\n",
       " 9.927157021844518,\n",
       " 9.896645688218824,\n",
       " 9.910303243059953,\n",
       " 9.879328727458235,\n",
       " 9.8739117453459,\n",
       " 9.86500782810454,\n",
       " 9.848491234181113,\n",
       " 9.820326164639743,\n",
       " 9.813705058643299,\n",
       " 9.809676241082899,\n",
       " 9.775894617858409,\n",
       " 9.790398815901078,\n",
       " 9.775062686666791,\n",
       " 9.727763809665102,\n",
       " 9.781545248374728,\n",
       " 9.732404749771765,\n",
       " 9.722108445132351,\n",
       " 9.680293871819753,\n",
       " 9.679757194853357,\n",
       " 9.656750643649225,\n",
       " 9.679310119811898,\n",
       " 9.654526873620235,\n",
       " 9.657162427110425,\n",
       " 9.649499584519996,\n",
       " 9.634698926214803,\n",
       " 9.623426527202788,\n",
       " 9.582538917407778,\n",
       " 9.601579944497985,\n",
       " 9.587531858176762,\n",
       " 9.567461146859666,\n",
       " 9.548378286788385,\n",
       " 9.57373265023601,\n",
       " 9.543334770730501,\n",
       " 9.521305851830768,\n",
       " 9.527454695578431,\n",
       " 9.556335609249523,\n",
       " 9.52163703239272,\n",
       " 9.512839782194018,\n",
       " 9.50772826055759,\n",
       " 9.513583831417604,\n",
       " 9.494023047074181,\n",
       " 9.487156545544023,\n",
       " 9.470965019715228,\n",
       " 9.461671593180442,\n",
       " 9.451829267339953,\n",
       " 9.479915231620254,\n",
       " 9.4474647365373,\n",
       " 9.428679575251477,\n",
       " 9.448111708665685,\n",
       " 9.410753320064051,\n",
       " 9.428137413953943,\n",
       " 9.435327930731967,\n",
       " 9.432127939203129,\n",
       " 9.398370987902709,\n",
       " 9.388641781384655,\n",
       " 9.395343346305438,\n",
       " 9.388112670381132,\n",
       " 9.38834895973276,\n",
       " 9.387137269621846,\n",
       " 9.362670832014611,\n",
       " 9.384957205765362,\n",
       " 9.386001741314287,\n",
       " 9.403424760072433,\n",
       " 9.353124571154478,\n",
       " 9.35832325778764,\n",
       " 9.349739021480744,\n",
       " 9.366302435336518,\n",
       " 9.359071907698008,\n",
       " 9.314573493786844,\n",
       " 9.352933874253416,\n",
       " 9.316433197061954,\n",
       " 9.318236832645107,\n",
       " 9.335737071178055,\n",
       " 9.311636442715832,\n",
       " 9.318247704048439,\n",
       " 9.301282801047462,\n",
       " 9.306616269442427,\n",
       " 9.314209826626021,\n",
       " 9.304530478491554,\n",
       " 9.341825161912784,\n",
       " 9.320374099530857,\n",
       " 9.313647773345018,\n",
       " 9.328568023773137,\n",
       " 9.291018232472268,\n",
       " 9.29493547242506,\n",
       " 9.28862671878505,\n",
       " 9.304822728202792,\n",
       " 9.285720785165624,\n",
       " 9.289098130644907,\n",
       " 9.294778783910829,\n",
       " 9.297672031814322,\n",
       " 9.267077177301104,\n",
       " 9.254605876739614,\n",
       " 9.257788915827705,\n",
       " 9.295321892548312,\n",
       " 9.257578638558899,\n",
       " 9.253463492974143,\n",
       " 9.236034448824245,\n",
       " 9.265038253812332,\n",
       " 9.273027485411106,\n",
       " 9.208270101001782,\n",
       " 9.250376828570207,\n",
       " 9.252275640234297,\n",
       " 9.256293832947847,\n",
       " 9.253091464887246,\n",
       " 9.265800497628666,\n",
       " 9.27866335909305,\n",
       " 9.222099821593929,\n",
       " 9.252689175676156,\n",
       " 9.21063966839076,\n",
       " 9.249070248040766,\n",
       " 9.23202859202874,\n",
       " 9.240616040476134,\n",
       " 9.229303098340756,\n",
       " 9.230427042232668,\n",
       " 9.241572162234036,\n",
       " 9.227754077524276,\n",
       " 9.23912124237891,\n",
       " 9.238688514945252,\n",
       " 9.235989134602,\n",
       " 9.226869667632114,\n",
       " 9.225888356511444,\n",
       " 9.209911115143132,\n",
       " 9.243883724142265,\n",
       " 9.217853283090346,\n",
       " 9.21054032359176,\n",
       " 9.227786823920217,\n",
       " 9.221849675152134,\n",
       " 9.204699234153072,\n",
       " 9.228312236796446,\n",
       " 9.214110163305078,\n",
       " 9.213102015358055,\n",
       " 9.182997452552907,\n",
       " 9.186857314655262,\n",
       " 9.190418223965212,\n",
       " 9.198119945983604,\n",
       " 9.21468968769721,\n",
       " 9.176769017381421,\n",
       " 9.166525435623647,\n",
       " 9.227827384111187,\n",
       " 9.208992653403335,\n",
       " 9.222685977365698,\n",
       " 9.198562674592782,\n",
       " 9.204154407450194,\n",
       " 9.211851439264867,\n",
       " 9.208863877282372,\n",
       " 9.1756464033989,\n",
       " 9.23629617858197,\n",
       " 9.2081166026777,\n",
       " 9.19884450250886,\n",
       " 9.21340055509687,\n",
       " 9.185652054983752,\n",
       " 9.194810281292538,\n",
       " 9.230489497783,\n",
       " 9.210493159448088,\n",
       " 9.216485482036408,\n",
       " 9.189905158092175,\n",
       " 9.213136828781494,\n",
       " 9.191637919705732,\n",
       " 9.17465572876244,\n",
       " 9.208506955783745,\n",
       " 9.250607009391503,\n",
       " 9.17636520378704,\n",
       " 9.213747198555302,\n",
       " 9.203330985734384,\n",
       " 9.187501439749095,\n",
       " 9.193640512953825,\n",
       " 9.17189690670844,\n",
       " 9.182795039754073,\n",
       " 9.178872772336446,\n",
       " 9.189940108056438,\n",
       " 9.178727920028996,\n",
       " 9.189872697622574,\n",
       " 9.16978754979658,\n",
       " 9.171513787582791,\n",
       " 9.199484592302259,\n",
       " 9.167358711328893,\n",
       " 9.177058125509987,\n",
       " 9.17929798734144,\n",
       " 9.180293139100515,\n",
       " 9.195142353152876,\n",
       " 9.176665723499777,\n",
       " 9.162618786206545,\n",
       " 9.20756423314999,\n",
       " 9.207900430883429,\n",
       " 9.178175807615048,\n",
       " 9.184382274098063,\n",
       " 9.170627051613868,\n",
       " 9.197983599456913,\n",
       " 9.187944786047144,\n",
       " 9.163326267650646,\n",
       " 9.185903114938208,\n",
       " 9.183313244823161,\n",
       " 9.195518064498902,\n",
       " 9.172646942437796,\n",
       " 9.20573041878943,\n",
       " 9.189723285185895,\n",
       " 9.167344898579305,\n",
       " 9.181352469050136,\n",
       " 9.18980956429485,\n",
       " 9.172963606827373,\n",
       " 9.163337823825568,\n",
       " 9.173301962644851,\n",
       " 9.172748833916724,\n",
       " 9.17208852741551,\n",
       " 9.18317709008706,\n",
       " 9.173088705495715,\n",
       " 9.174100976236632,\n",
       " 9.160015242829974,\n",
       " 9.159725695782482,\n",
       " 9.169072803448048,\n",
       " 9.193514298952813,\n",
       " 9.16363651476443,\n",
       " 9.173286500540167,\n",
       " 9.184753088933515,\n",
       " 9.19054284104562,\n",
       " 9.191060915820273,\n",
       " 9.1743282384978,\n",
       " 9.1587604096015,\n",
       " 9.1665837784095,\n",
       " 9.177249487827625,\n",
       " 9.183274237740084,\n",
       " 9.201661523153861,\n",
       " 9.185924022576026,\n",
       " 9.145373781976664,\n",
       " 9.15263610924302,\n",
       " 9.180142988402025,\n",
       " 9.169445231479912,\n",
       " 9.184385722721634,\n",
       " 9.161640292845968,\n",
       " 9.178805421903125,\n",
       " 9.161770464837332,\n",
       " 9.17809500623893,\n",
       " 9.206428798538292,\n",
       " 9.151490749292268,\n",
       " 9.17435738969993,\n",
       " 9.17905046174447,\n",
       " 9.188582076269762,\n",
       " 9.174869216258235,\n",
       " 9.155445134331819,\n",
       " 9.170078662048846,\n",
       " 9.179139340319757,\n",
       " 9.211509117781016,\n",
       " 9.164442307306832,\n",
       " 9.163873196264035,\n",
       " 9.172353035585466,\n",
       " 9.173658057156524,\n",
       " 9.164092670243605,\n",
       " 9.167906400022472,\n",
       " 9.151699746842754,\n",
       " 9.169510816032156,\n",
       " 9.167452291500965,\n",
       " 9.17884258660883,\n",
       " 9.179986526957297,\n",
       " 9.159830225877656,\n",
       " 9.172971622882294,\n",
       " 9.1457416013598,\n",
       " 9.163939470294657,\n",
       " 9.187202633175023,\n",
       " 9.142156669662448,\n",
       " 9.140536418436199,\n",
       " 9.171512491764618,\n",
       " 9.16238757358706,\n",
       " 9.174180895288051,\n",
       " 9.165138617124944,\n",
       " 9.170795157210854,\n",
       " 9.167469792700341,\n",
       " 9.162832322595744,\n",
       " 9.164420040243225,\n",
       " 9.14704730598689,\n",
       " 9.158654383627692,\n",
       " 9.16998530393157,\n",
       " 9.17708970233523,\n",
       " 9.185464562701123,\n",
       " 9.172220953452191,\n",
       " 9.163106230528152,\n",
       " 9.183621809623338,\n",
       " 9.14729088399683,\n",
       " 9.15375748441668,\n",
       " 9.179236863460048,\n",
       " 9.16708721023644,\n",
       " 9.196086381282313,\n",
       " 9.15225959835897,\n",
       " 9.170077386553437,\n",
       " 9.161292917790009,\n",
       " 9.171183615373069,\n",
       " 9.175552342738612,\n",
       " 9.152916586267112,\n",
       " 9.181223699087587,\n",
       " 9.179168051459252,\n",
       " 9.1752765106539,\n",
       " 9.181595379180134,\n",
       " 9.180942163520193,\n",
       " 9.162257139357253,\n",
       " 9.17740529498491,\n",
       " 9.151174185108875,\n",
       " 9.175038408045399,\n",
       " 9.164072869316678,\n",
       " 9.167275569447732,\n",
       " 9.16771828415649,\n",
       " 9.151144114719546,\n",
       " 9.158879259151727,\n",
       " 9.178848191908804,\n",
       " 9.17029345695383,\n",
       " 9.151759352147359,\n",
       " 9.156705487346297,\n",
       " 9.16287999821765,\n",
       " 9.170123237833325,\n",
       " 9.149069616011587,\n",
       " 9.172561302748113,\n",
       " 9.181322470098404,\n",
       " 9.19281095173966,\n",
       " 9.178082680262323,\n",
       " 9.233835455764265,\n",
       " 9.167582085959586,\n",
       " 9.18740589882615,\n",
       " 9.159157764163844,\n",
       " 9.157347609812044,\n",
       " 9.17495374494813,\n",
       " 9.145716946503333,\n",
       " 9.154053315421312,\n",
       " 9.176342988190175,\n",
       " 9.168168956063331,\n",
       " 9.168951321264034,\n",
       " 9.195662793198196,\n",
       " 9.161832506014413,\n",
       " 9.180121031590494,\n",
       " 9.176349338482227,\n",
       " 9.17375331312088,\n",
       " 9.1604957706374,\n",
       " 9.185658036298857,\n",
       " 9.163676788446208,\n",
       " 9.159420143370259,\n",
       " 9.19261127459607,\n",
       " 9.165297128881475,\n",
       " 9.171572011423287,\n",
       " 9.164172368163992,\n",
       " 9.176817091628633,\n",
       " 9.155452200231517,\n",
       " 9.174743018906934,\n",
       " 9.169125168305921,\n",
       " 9.17047942247778,\n",
       " 9.179964278984773,\n",
       " 9.149807969010624,\n",
       " 9.168563042707548,\n",
       " 9.185136157472195,\n",
       " 9.175334790096072,\n",
       " 9.20303458622021,\n",
       " 9.182027718853687,\n",
       " 9.150375162543407,\n",
       " 9.150247821596716,\n",
       " 9.168475541241495,\n",
       " 9.171602483341175,\n",
       " 9.131729434513078,\n",
       " 9.138559745774497,\n",
       " 9.182724649879765,\n",
       " 9.194332678555563,\n",
       " 9.182610235970838,\n",
       " 9.215272044607634,\n",
       " 9.171603067334727,\n",
       " 9.151887066601827,\n",
       " 9.167986083998452,\n",
       " 9.172061405674558,\n",
       " 9.169311845434548,\n",
       " 9.15895061193797,\n",
       " 9.16876032268869,\n",
       " 9.163577139465572,\n",
       " 9.172089569100155,\n",
       " 9.168743277123934,\n",
       " 9.182428044146718,\n",
       " 9.194958162439706,\n",
       " 9.164055444877526,\n",
       " 9.163367164266946,\n",
       " 9.180416589557465,\n",
       " 9.187513152787606,\n",
       " 9.199404937754698,\n",
       " 9.173226533692702,\n",
       " 9.179695483943194,\n",
       " 9.185981084675806,\n",
       " 9.164137503933643,\n",
       " 9.156373342068873,\n",
       " 9.189256501087844,\n",
       " 9.156560042775425,\n",
       " 9.153703004055798,\n",
       " 9.148469985455165,\n",
       " 9.149348684782472,\n",
       " 9.186624979356997,\n",
       " 9.19735512188,\n",
       " 9.178606841836908,\n",
       " 9.177964833301811,\n",
       " 9.18022948384725,\n",
       " 9.165272432763638,\n",
       " 9.17183972240814,\n",
       " 9.162008333909995,\n",
       " 9.18526877151644,\n",
       " 9.172795610498238,\n",
       " 9.171872416193635,\n",
       " 9.154324173751352,\n",
       " 9.186483989782438,\n",
       " 9.149781608977442,\n",
       " 9.198384574418577,\n",
       " 9.13664466023885,\n",
       " 9.144807805390375,\n",
       " 9.184632726876938,\n",
       " 9.164286337479455,\n",
       " 9.155912306343938,\n",
       " 9.171048878567685,\n",
       " 9.148599708388213,\n",
       " 9.176221606212348,\n",
       " 9.16703835008769,\n",
       " 9.172175799964538,\n",
       " 9.174958323112714,\n",
       " 9.17536511570765,\n",
       " 9.16591120241313,\n",
       " 9.173069935707149,\n",
       " 9.171797764741187,\n",
       " 9.15502421706365,\n",
       " 9.164810033038094,\n",
       " 9.149927019809004,\n",
       " 9.149921166324967,\n",
       " 9.181767182200597,\n",
       " 9.185900431717453,\n",
       " 9.161095181206495,\n",
       " 9.155189306621622,\n",
       " 9.160622119111768,\n",
       " 9.160918212888205,\n",
       " 9.160829225325497,\n",
       " 9.149919062786877,\n",
       " 9.146544687334462,\n",
       " 9.153428411483764,\n",
       " 9.167976883856573,\n",
       " 9.165221685413066,\n",
       " 9.160956323982605,\n",
       " 9.169811641070236,\n",
       " 9.177996809544158,\n",
       " 9.172612404251451,\n",
       " 9.189935397573942,\n",
       " 9.1680794919109,\n",
       " 9.163051912397476,\n",
       " 9.132107972394936,\n",
       " 9.161463816667395,\n",
       " 9.14130275126313,\n",
       " 9.164936147756682,\n",
       " 9.1740307568624,\n",
       " 9.150259786558328,\n",
       " 9.144513464149954,\n",
       " 9.168590930731094,\n",
       " 9.168043484019178,\n",
       " 9.17384153652895,\n",
       " 9.162614175358382,\n",
       " 9.16731076891572,\n",
       " 9.164041170818779,\n",
       " 9.153537766959834,\n",
       " 9.17761582897158,\n",
       " 9.16651285442479,\n",
       " 9.147521017662273,\n",
       " 9.186611870646036,\n",
       " 9.178777598762863,\n",
       " 9.180627597302088,\n",
       " 9.156322608398776,\n",
       " 9.182866119722599,\n",
       " 9.154409200063052,\n",
       " 9.16419285153111,\n",
       " 9.177737895764988,\n",
       " 9.185817767421257,\n",
       " 9.16010663043089,\n",
       " 9.174918802022054,\n",
       " 9.176317028541847,\n",
       " 9.158369515038943,\n",
       " 9.1744508483753,\n",
       " 9.155343379745624,\n",
       " 9.181745605539131,\n",
       " 9.179109314358982,\n",
       " 9.156712316498986,\n",
       " 9.154140354918377,\n",
       " 9.162180960926182,\n",
       " 9.14085331191876,\n",
       " 9.17602795841949,\n",
       " 9.17549919862149,\n",
       " 9.157198764565246,\n",
       " 9.149844921998872,\n",
       " 9.154698491184474,\n",
       " 9.163730196935225,\n",
       " 9.178046388555718,\n",
       " 9.154094275161349,\n",
       " 9.193975248987824,\n",
       " 9.158063159349659,\n",
       " 9.163650974664302,\n",
       " 9.145036362985843,\n",
       " 9.167672943101158,\n",
       " 9.14717066798263,\n",
       " 9.181357244371927,\n",
       " 9.171103625367929,\n",
       " 9.166239661308232,\n",
       " 9.172937697326125,\n",
       " 9.163534300265717,\n",
       " 9.155556271964773,\n",
       " 9.15618878924099,\n",
       " 9.162553388078274,\n",
       " 9.165561227736879,\n",
       " 9.15579383720771,\n",
       " 9.166150375309906,\n",
       " 9.152804830461411,\n",
       " 9.1527893179897,\n",
       " 9.143149307029274,\n",
       " 9.159747215654578,\n",
       " 9.171457735022935,\n",
       " 9.148322657773415,\n",
       " 9.166174058896589,\n",
       " 9.158913227728812,\n",
       " 9.157225830088683,\n",
       " 9.164620136334888,\n",
       " 9.158626244692785,\n",
       " 9.152429436405646,\n",
       " 9.168168627819892,\n",
       " 9.177213148789212,\n",
       " 9.184944477204468,\n",
       " 9.177015131601989,\n",
       " 9.17428874256866,\n",
       " 9.160403009446345,\n",
       " 9.14838483782272,\n",
       " 9.1731081521819,\n",
       " 9.175654860440215,\n",
       " 9.169550865074806,\n",
       " 9.149658498816825,\n",
       " 9.178074879487943,\n",
       " 9.16594434206776,\n",
       " 9.168996776689902,\n",
       " 9.149297728749659,\n",
       " 9.172331969192546,\n",
       " 9.152757123123676,\n",
       " 9.167301401264993,\n",
       " 9.165562124357892,\n",
       " 9.15026831266185,\n",
       " 9.167159024991673,\n",
       " 9.185059226175076,\n",
       " 9.15999725287251,\n",
       " 9.148547725395963,\n",
       " 9.164516458828071,\n",
       " 9.162535499338734,\n",
       " 9.16880868035489,\n",
       " 9.172492251097056,\n",
       " 9.16216247398475,\n",
       " 9.162905084339014,\n",
       " 9.15420246537761,\n",
       " 9.173149079634255,\n",
       " 9.177174686109888,\n",
       " 9.15000178857923,\n",
       " 9.148334897400268,\n",
       " 9.198214838425612,\n",
       " 9.171211860276676,\n",
       " 9.168263298471036,\n",
       " 9.158590412799722,\n",
       " 9.167309879200925,\n",
       " 9.173326959205289,\n",
       " 9.193673510613037,\n",
       " 9.177624110014236,\n",
       " 9.15267812673456,\n",
       " 9.167230220298485,\n",
       " 9.175807027887155,\n",
       " 9.15386526981623,\n",
       " 9.16527799161158,\n",
       " 9.148119825135737,\n",
       " 9.194341644765705,\n",
       " 9.175051223219981,\n",
       " 9.205752207872173,\n",
       " 9.170429636939426,\n",
       " 9.170345299006389,\n",
       " 9.16758658648417,\n",
       " 9.14659753215269,\n",
       " 9.185820505099983,\n",
       " 9.165975772850627,\n",
       " 9.184732884674494,\n",
       " 9.191492461190453,\n",
       " 9.171176517174693,\n",
       " 9.154127087100406,\n",
       " 9.160519990742866,\n",
       " 9.157936269858666,\n",
       " 9.16589586259694,\n",
       " 9.183938903826188,\n",
       " 9.188744558179511,\n",
       " 9.157261121888881,\n",
       " 9.16161247738173,\n",
       " 9.169860933539612,\n",
       " 9.174504074399321,\n",
       " 9.222272850050697,\n",
       " 9.173690647128764,\n",
       " 9.154871771608331,\n",
       " 9.148892348630842,\n",
       " 9.168189665092314,\n",
       " 9.183157673797044,\n",
       " 9.15479701629864,\n",
       " 9.183974726965507,\n",
       " 9.128858358041827,\n",
       " 9.180826293498388,\n",
       " 9.181525266698365,\n",
       " 9.186407456802707,\n",
       " 9.182145382645386,\n",
       " 9.166661265767369,\n",
       " 9.169654272667156,\n",
       " 9.175874805450439,\n",
       " 9.159244802253273,\n",
       " 9.164142166292535,\n",
       " 9.170848229098583,\n",
       " 9.173738634498356,\n",
       " 9.156516339594148,\n",
       " 9.173098061357477,\n",
       " 9.168983961119423,\n",
       " 9.158490851268557,\n",
       " 9.142755249065667,\n",
       " 9.178516380725311,\n",
       " 9.168191152965012,\n",
       " 9.176546595193363,\n",
       " 9.165279574939685,\n",
       " 9.179352460752114,\n",
       " 9.15480539288468,\n",
       " 9.158030505109977,\n",
       " 9.151402445033028,\n",
       " 9.159067991298944,\n",
       " 9.155366572462764,\n",
       " 9.163161839814205,\n",
       " 9.161697720865481,\n",
       " 9.155781791174984,\n",
       " 9.182336058563852,\n",
       " 9.167044045564433,\n",
       " 9.16877782186459,\n",
       " 9.167744028524279,\n",
       " 9.185833172780562,\n",
       " 9.154167315792774,\n",
       " 9.18010958701482,\n",
       " 9.184059728511585,\n",
       " 9.150528452229237,\n",
       " 9.15848351756585,\n",
       " 9.14846107176749,\n",
       " 9.168818778305477,\n",
       " 9.155020318172074,\n",
       " 9.166293295811023,\n",
       " 9.166002533708552,\n",
       " 9.182892678496582,\n",
       " 9.241128120651105,\n",
       " 9.207624846542894,\n",
       " 9.167711163358934,\n",
       " 9.178514898659119,\n",
       " 9.150382292754536,\n",
       " 9.142879991513777,\n",
       " 9.180082443279534,\n",
       " 9.176629475649872,\n",
       " 9.17301586166959,\n",
       " 9.179424716097841,\n",
       " 9.175818575264342,\n",
       " 9.154332350013,\n",
       " 9.153461385916959,\n",
       " 9.173553396239052,\n",
       " 9.166802790200139,\n",
       " 9.158580393632839,\n",
       " 9.155158976523198,\n",
       " 9.173470974100471,\n",
       " 9.144821529194878,\n",
       " 9.162869359074483,\n",
       " 9.161453886313632,\n",
       " 9.171151642605828,\n",
       " 9.151944938445004,\n",
       " 9.19620524702037,\n",
       " 9.168898218056373,\n",
       " 9.165166247814783,\n",
       " 9.169466600250933,\n",
       " 9.163388882088045,\n",
       " 9.16187521469989,\n",
       " 9.158292603008862,\n",
       " 9.186095200165612,\n",
       " 9.186445325063163,\n",
       " 9.177918267689948,\n",
       " 9.140275094429946,\n",
       " 9.167831002082332,\n",
       " 9.17187379910937,\n",
       " 9.16418808078414,\n",
       " 9.168172794514476,\n",
       " 9.174477433806416,\n",
       " 9.163362887688669,\n",
       " 9.159979433327143,\n",
       " 9.17173303150163,\n",
       " 9.163142939687216,\n",
       " 9.176652303481013,\n",
       " 9.150517705621754,\n",
       " 9.176423092081977,\n",
       " 9.127321480297075,\n",
       " 9.166623049336605,\n",
       " 9.15378215370143,\n",
       " 9.14276354831963,\n",
       " 9.166135199307515,\n",
       " 9.172983454074368,\n",
       " 9.16015169682098,\n",
       " 9.187633431529648,\n",
       " 9.155263370165526,\n",
       " 9.175334979863184,\n",
       " 9.143202397656177,\n",
       " 9.14011630708441,\n",
       " 9.17150149310207,\n",
       " 9.169939593987271,\n",
       " 9.151365027502454,\n",
       " 9.168608126605129,\n",
       " 9.171533504887261,\n",
       " 9.183430805065536,\n",
       " 9.165075888921853,\n",
       " 9.154921045910388,\n",
       " 9.180290569018613,\n",
       " 9.178525200585158,\n",
       " 9.14784024764691,\n",
       " 9.154046192336347,\n",
       " 9.152193417848256,\n",
       " 9.172029573934985,\n",
       " 9.171134651455052,\n",
       " 9.18967027189107,\n",
       " 9.170860963378006,\n",
       " 9.165767706452261,\n",
       " 9.17533118460891,\n",
       " 9.165977677471963,\n",
       " 9.17573884483633,\n",
       " 9.17747334413423,\n",
       " 9.139917658527839,\n",
       " 9.15103555156736,\n",
       " 9.16579926528614,\n",
       " 9.15333798763057,\n",
       " 9.173910071577094,\n",
       " 9.162723077971117,\n",
       " 9.151912682091067,\n",
       " 9.159051903147539,\n",
       " 9.160975967562067,\n",
       " 9.166357741628627,\n",
       " 9.162148020628194,\n",
       " 9.172925944345904,\n",
       " 9.16349886774577,\n",
       " 9.161588978767394,\n",
       " 9.192424384342349,\n",
       " 9.164051590546471,\n",
       " 9.16403363014939,\n",
       " 9.14423333850734,\n",
       " 9.14749155924329,\n",
       " 9.153581242983632,\n",
       " 9.174723062128159,\n",
       " 9.153105472198712,\n",
       " 9.176977571526137,\n",
       " 9.188740945236269,\n",
       " 9.17724475623057,\n",
       " 9.143962844799365,\n",
       " 9.173298029882002,\n",
       " 9.156069380330864,\n",
       " 9.146245956772807,\n",
       " 9.186052882451413,\n",
       " 9.160817979028744,\n",
       " 9.165947785764603,\n",
       " 9.151400917042665,\n",
       " 9.1664058144682,\n",
       " 9.162290326431668,\n",
       " 9.165911833210625,\n",
       " 9.157614667609169,\n",
       " 9.152934940758666,\n",
       " 9.184902079782802,\n",
       " 9.179166152644422,\n",
       " 9.163925131484591,\n",
       " 9.178270329848427,\n",
       " 9.16308328089239,\n",
       " 9.182326607246681,\n",
       " 9.153654278248439,\n",
       " 9.188104911835872,\n",
       " 9.151819147395033,\n",
       " 9.177580028794349,\n",
       " 9.190744527767505,\n",
       " 9.157210471269389,\n",
       " 9.17921062967434,\n",
       " 9.169248612076593,\n",
       " 9.183228552363456,\n",
       " 9.162433689854682,\n",
       " 9.163208291275474,\n",
       " 9.155476250771667,\n",
       " 9.158815797932473,\n",
       " 9.167012294895974,\n",
       " 9.163400187351607,\n",
       " 9.176375456401782,\n",
       " 9.183184293363366,\n",
       " 9.167622683760865,\n",
       " 9.179134989796529,\n",
       " 9.156445769630235,\n",
       " 9.173741364039179,\n",
       " 9.158835905416426,\n",
       " 9.161545493066091,\n",
       " 9.153656105713651,\n",
       " 9.179731273915055,\n",
       " 9.167190488326154,\n",
       " 9.174717437649125,\n",
       " 9.168413597015437,\n",
       " 9.171409044406511,\n",
       " 9.125086328024354,\n",
       " 9.170510952235148,\n",
       " 9.151383409992794,\n",
       " 9.172608437397383,\n",
       " 9.167414972175091,\n",
       " 9.16524626372925,\n",
       " 9.186449321169695,\n",
       " 9.162974324877412,\n",
       " 9.163834213946577,\n",
       " 9.175321509983267,\n",
       " 9.159871529213177,\n",
       " 9.17337870677019,\n",
       " 9.18273151545507,\n",
       " 9.148781130322671,\n",
       " 9.157073585089723,\n",
       " 9.168133208496544,\n",
       " 9.13868206664645,\n",
       " 9.16926552563136,\n",
       " 9.1891824796191,\n",
       " 9.172610180580309,\n",
       " 9.185905613274592,\n",
       " 9.141211051958514,\n",
       " 9.154695299630676,\n",
       " 9.166674287160824,\n",
       " 9.182943439043756,\n",
       " 9.194190294012373,\n",
       " 9.185427875888303,\n",
       " 9.174515296084415,\n",
       " 9.16603694032479,\n",
       " 9.158383899421269,\n",
       " 9.154541707038879,\n",
       " 9.165149846859963,\n",
       " 9.146080177912413,\n",
       " 9.177806347410618,\n",
       " 9.152136127271335,\n",
       " 9.168670534779665,\n",
       " 9.162414170455229,\n",
       " 9.180684632480805,\n",
       " 9.163463482645605,\n",
       " 9.136170398089279,\n",
       " 9.15649266471722,\n",
       " 9.180546470299857,\n",
       " 9.201634439771025,\n",
       " 9.140571711116172,\n",
       " 9.19612450744833,\n",
       " 9.164660034320452,\n",
       " 9.177446338963245,\n",
       " 9.193477457211905,\n",
       " 9.165725464222616,\n",
       " 9.168684112805723,\n",
       " 9.191541397615552,\n",
       " 9.172713243389481,\n",
       " 9.17277732942377,\n",
       " 9.183797257412843,\n",
       " 9.16174435136063,\n",
       " 9.162390777369707,\n",
       " 9.16883239042275,\n",
       " 9.17255439124864,\n",
       " 9.175712599701548,\n",
       " 9.1785049595956,\n",
       " 9.180710223592076,\n",
       " 9.160717050967621,\n",
       " 9.170948119181109,\n",
       " 9.187534240251098,\n",
       " 9.179565547181232,\n",
       " 9.180368714622906,\n",
       " 9.190160793923804,\n",
       " 9.166698735754428,\n",
       " 9.196296351488225,\n",
       " 9.157925800291814,\n",
       " 9.207299996478092,\n",
       " 9.159809182094913,\n",
       " 9.158856619735046,\n",
       " 9.18028615101677,\n",
       " 9.163297011667511,\n",
       " 9.162957800402413,\n",
       " 9.175514749407329,\n",
       " 9.146466650294203,\n",
       " 9.15773221579865,\n",
       " 9.210369926097208,\n",
       " 9.164794899220835,\n",
       " 9.166353761665935,\n",
       " 9.158304509201614,\n",
       " 9.156095012527551,\n",
       " 9.173603370004914,\n",
       " 9.166752040650133,\n",
       " 9.183668916867667,\n",
       " 9.156517253150799,\n",
       " 9.164141773781653,\n",
       " 9.148247124964021,\n",
       " 9.173145936336025,\n",
       " 9.150147815911971,\n",
       " 9.149240809525072,\n",
       " 9.170470756886191,\n",
       " 9.146011540898538,\n",
       " 9.186830191330715,\n",
       " 9.166880306106652,\n",
       " 9.164915930916901,\n",
       " 9.162142179724915,\n",
       " 9.161925736564552,\n",
       " 9.171852542465464,\n",
       " 9.179824641357929,\n",
       " 9.167534049850548,\n",
       " 9.192824133999673,\n",
       " 9.153813685636239,\n",
       " 9.157729656054086,\n",
       " 9.168262898877979,\n",
       " 9.164347163535572,\n",
       " 9.171601835564054,\n",
       " 9.1699453962685,\n",
       " 9.166616223527056,\n",
       " 9.172702896023148,\n",
       " 9.162213335705859,\n",
       " 9.16724505046197,\n",
       " 9.168101560673591,\n",
       " 9.180140758132582,\n",
       " 9.188746445293356,\n",
       " 9.188832593755969,\n",
       " 9.169196437117797,\n",
       " 9.153161156617408,\n",
       " 9.184566143913903,\n",
       " 9.164267920897895,\n",
       " 9.190737504184906,\n",
       " 9.165251012745818,\n",
       " 9.148761245663316,\n",
       " 9.151326001372285,\n",
       " 9.153354812636147,\n",
       " 9.17823276766112,\n",
       " 9.173905890894112,\n",
       " 9.162862747973621,\n",
       " 9.16262762124248,\n",
       " 9.170319050880376,\n",
       " 9.17545137255834,\n",
       " 9.182301212984697,\n",
       " 9.152050270365613,\n",
       " 9.155732191708696,\n",
       " 9.13966677461603,\n",
       " 9.17168711419475,\n",
       " 9.155665965845664,\n",
       " 9.163663016122205,\n",
       " 9.16591886519506,\n",
       " 9.144272797354033,\n",
       " 9.14664844437279,\n",
       " 9.161529535033166,\n",
       " 9.17995073487398,\n",
       " 9.204176592035047,\n",
       " 9.159506813098584,\n",
       " 9.134975077481288,\n",
       " 9.160259455728355,\n",
       " 9.189641989377153,\n",
       " 9.156325485521577,\n",
       " 9.168515815066236,\n",
       " 9.187136591756476,\n",
       " 9.17091429831797,\n",
       " 9.166073432531745,\n",
       " 9.182611986631837,\n",
       " 9.168144078184318,\n",
       " 9.17533126255683,\n",
       " 9.181872971559363,\n",
       " 9.17089220932049,\n",
       " 9.146904925226725]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[ 0.7534,  0.9320, 23.0112,  0.6130,  0.1556,  0.3211]])), ('0.bias', tensor([0.0732]))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Function #2\n",
    "\n",
    "def mini_batch(device, data_loader, step_fn):\n",
    "    mini_batch_losses = []\n",
    "    for x_batch, y_batch in data_loader:\n",
    "        # Send each mini batch to device\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        mini_batch_loss = step_fn(x_batch, y_batch)\n",
    "        mini_batch_losses.append(mini_batch_loss)\n",
    "    \n",
    "    loss = np.mean(mini_batch_losses)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model_training/v3.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_training/v3.py\n",
    "\n",
    "# Define epochs\n",
    "n_epochs = 200\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    loss = mini_batch(device, train_loader, train_step_fn)\n",
    "    losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i data_preparation/v1.py\n",
    "%run -i model_configuration/v1.py\n",
    "%run -i model_training/v3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[ 0.7268,  1.0011, 20.4338,  0.5707,  0.6372,  0.3646]])), ('0.bias', tensor([0.0553]))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we're going to add the entire dataset into a TensorDataset, and then\n",
    "# perform the training-test splits using random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting data_preparation/v2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile data_preparation/v2.py\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Build tensors BEFORE split\n",
    "X_tensor = torch.as_tensor(X).float()\n",
    "y_tensor = torch.as_tensor(y).float()\n",
    "\n",
    "# Build dataset with ALL points\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "# Perform the split\n",
    "ratio = 0.8\n",
    "n_total = len(dataset)\n",
    "n_train = int(n_total * ratio)\n",
    "n_val = n_total - n_train\n",
    "train_data, val_data = random_split(dataset, [n_train, n_val])\n",
    "\n",
    "# Builds a loader of each set\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_data,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i data_preparation/v2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model next\n",
    "\n",
    "# Helper function #3\n",
    "\n",
    "def make_val_step_fn(model, loss_fn):\n",
    "    # Builds the function that performs a step in the validation\n",
    "    # loop\n",
    "    def perform_val_step_fn(X, y):\n",
    "        # Step 1 - Computes the predicted output\n",
    "        yhat = model(X)\n",
    "        # Step 2 - Compute the loss\n",
    "        loss = loss_fn(yhat, y)\n",
    "        # No need to compute step 3 and 4 since we don't\n",
    "        # update the parameters\n",
    "        return loss.item()\n",
    "    \n",
    "    return perform_val_step_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_configuration/v2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_configuration/v2.py\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Set the learning rate\n",
    "lr = 0.001\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Now we create a model and send it at once to the device\n",
    "model = nn.Sequential(nn.Linear(6,1)).to(device)\n",
    "\n",
    "# Define an SGD optimizer to update the parameters\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# Define the MSE loss function\n",
    "loss_fn = nn.MSELoss(reduction=\"mean\")\n",
    "\n",
    "# Create the train_step function for our model, loss, and optimizer\n",
    "train_step_fn = make_train_step_fn(model, loss_fn, optimizer)\n",
    "\n",
    "# Create the val_step function for our model, loss\n",
    "val_step_fn = make_val_step_fn(model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_configuration/v2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model_training/v4.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_training/v4.py\n",
    "\n",
    "# This time we also include the validatiion step\n",
    "\n",
    "# Define number of epochs\n",
    "n_epochs = 200\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    loss = mini_batch(device, train_loader, train_step_fn)\n",
    "    losses.append(loss)\n",
    "\n",
    "    # VALIDATION - no gradients because its in validation!\n",
    "    with torch.no_grad():\n",
    "        val_loss = mini_batch(device, val_loader, val_step_fn)\n",
    "        val_losses.append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_training/v4.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[ 0.7365,  0.9475, 21.3789,  0.5911,  0.4888,  0.3591]])), ('0.bias', tensor([0.0197]))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-800507e67ff67a47\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-800507e67ff67a47\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we do not specify \"test\" or any other name, TensorBoard will\n",
    "# default to runs/CURRENT_DATETIME_HOSTNAME\n",
    "\n",
    "writer = SummaryWriter(\"runs/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_x, dummy_y = next(iter(train_loader))\n",
    "\n",
    "# Since our model was sent to device, we need to do the same with the data.\n",
    "writer.add_graph(model, dummy_x.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now send loss values to TensorBoard using add_scalars\n",
    "\n",
    "writer.add_scalars(\n",
    "    main_tag=\"loss\",\n",
    "    tag_scalar_dict={\n",
    "        \"training\": loss,\n",
    "        \"validation\": val_loss\n",
    "    },\n",
    "    global_step=epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rework the model config to incorporate TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i data_preparation/v2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model_configuration/v3.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_configuration/v3.py\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Set learning rate\n",
    "lr = 0.001\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "model = nn.Sequential(nn.Linear(6,1)).to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "loss_fn = nn.MSELoss(reduction=\"mean\")\n",
    "\n",
    "# Create train_step\n",
    "train_step_fn = make_train_step_fn(model, loss_fn, optimizer)\n",
    "\n",
    "# Create val step\n",
    "val_step_fn = make_val_step_fn(model, loss_fn)\n",
    "\n",
    "# Create a Summary Writer to interface with TensorBoard\n",
    "writer = SummaryWriter(\"runs/simple_linear_regression\")\n",
    "\n",
    "# Fetches a single mini-batch so we can use add_graph\n",
    "x_dummy, y_dummy = next(iter(train_loader))\n",
    "writer.add_graph(model, x_dummy.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_configuration/v3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model_training/v5.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_training/v5.py\n",
    "\n",
    "# Define the number of epochs\n",
    "n_epochs = 200\n",
    "\n",
    "# Define the learning rate\n",
    "lr = 0.001\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    loss = mini_batch(device, train_loader, train_step_fn)\n",
    "    losses.append(loss)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_loss = mini_batch(device, val_loader, val_step_fn)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "    # Records both losses for each epoch under tag \"loss\"\n",
    "    writer.add_scalars(\n",
    "        main_tag=\"loss\",\n",
    "        tag_scalar_dict={\n",
    "            \"training\": loss,\n",
    "            \"validation\": val_loss\n",
    "        },\n",
    "        global_step=epoch\n",
    "    )\n",
    "\n",
    "# Close the writer\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_training/v5.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[ 0.7664,  0.9821, 21.3793,  0.5757,  0.5077,  0.3798]])), ('0.bias', tensor([0.0416]))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving and loading models, it is important to know how to checkpoint\n",
    "# and save our model\n",
    "\n",
    "# To save our model, we have to save its state (model.state_dict(),\n",
    "# optimizer.state_dict()), losses, epoch, anything else we need restored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "    \"epoch\": n_epochs,\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    \"loss\": losses,\n",
    "    \"val_loss\": val_losses,\n",
    "}\n",
    "\n",
    "torch.save(checkpoint, \"model_checkpoint.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The procedure is the same, whether you are checkpointing a partially\n",
    "# trained model or saving a fully trained model to deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resuming training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i data_preparation/v2.py\n",
    "%run -i model_configuration/v3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[-0.0031,  0.2190, -0.3360, -0.3004, -0.1572,  0.1095]])), ('0.bias', tensor([-0.0081]))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=6, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we're ready to load the model back\n",
    "\n",
    "checkpoint = torch.load(\"model_checkpoint.pth\")\n",
    "\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "saved_epoch = checkpoint[\"epoch\"]\n",
    "saved_losses = checkpoint[\"loss\"]\n",
    "saved_val_losses = checkpoint[\"val_loss\"]\n",
    "\n",
    "model.train() # always use TRAIN for resuming training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[ 0.7664,  0.9821, 21.3793,  0.5757,  0.5077,  0.3798]])), ('0.bias', tensor([0.0416]))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_training/v5.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[ 0.7668,  0.9498, 23.1986,  0.5866,  0.1708,  0.3822]])), ('0.bias', tensor([0.0546]))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9.002713516855117,\n",
       " 9.015694255360645,\n",
       " 9.032064080777403,\n",
       " 9.002891363715632,\n",
       " 9.015014864908633,\n",
       " 8.993514223000185,\n",
       " 8.996778886370572,\n",
       " 9.024603309557419,\n",
       " 9.01635081777277,\n",
       " 8.980114790512301,\n",
       " 8.98494594218811,\n",
       " 9.001210643069996,\n",
       " 9.0012939201923,\n",
       " 9.00637609513539,\n",
       " 9.000493965407674,\n",
       " 9.015864338023102,\n",
       " 9.006960377944225,\n",
       " 9.00266551509384,\n",
       " 8.994626645662988,\n",
       " 9.010263282507273,\n",
       " 9.022635608680488,\n",
       " 9.012047090040621,\n",
       " 8.999719053660868,\n",
       " 9.000959707785022,\n",
       " 8.995504904856054,\n",
       " 9.010072109850187,\n",
       " 9.003563592908302,\n",
       " 9.005608755488728,\n",
       " 9.011860081160716,\n",
       " 9.012771334142956,\n",
       " 9.00289741181588,\n",
       " 8.99724913113185,\n",
       " 9.007617351081636,\n",
       " 8.992004445048881,\n",
       " 9.013758222801124,\n",
       " 9.001717307000813,\n",
       " 8.999141598240657,\n",
       " 8.999889146757988,\n",
       " 8.990330104757033,\n",
       " 8.9851806927713,\n",
       " 9.015739355861987,\n",
       " 9.007411543328017,\n",
       " 9.003004602914633,\n",
       " 8.992821498280655,\n",
       " 9.010519378484066,\n",
       " 8.98585090233682,\n",
       " 9.003536385467195,\n",
       " 8.991954147584678,\n",
       " 8.988353459255947,\n",
       " 9.002747203952582,\n",
       " 8.995660024249892,\n",
       " 8.98966702734161,\n",
       " 8.998746160696951,\n",
       " 8.988681641197944,\n",
       " 9.00998938769025,\n",
       " 8.978592580680083,\n",
       " 9.006278947265265,\n",
       " 8.99325017900584,\n",
       " 9.008312015878445,\n",
       " 9.0058569297464,\n",
       " 8.997701845427816,\n",
       " 8.97310536522274,\n",
       " 8.99540309018867,\n",
       " 8.991164615449978,\n",
       " 9.000636133882734,\n",
       " 9.004599949186163,\n",
       " 9.004414144990056,\n",
       " 9.005589388830717,\n",
       " 8.990840264762095,\n",
       " 8.993819090054016,\n",
       " 9.007823047942894,\n",
       " 9.004754506340323,\n",
       " 9.001725463750134,\n",
       " 8.997015506645198,\n",
       " 8.999626444946271,\n",
       " 8.971112680835626,\n",
       " 9.015787851209788,\n",
       " 8.989314715144554,\n",
       " 8.969891569334099,\n",
       " 8.981762580785333,\n",
       " 8.99622358632026,\n",
       " 8.991103531547296,\n",
       " 8.98596423760403,\n",
       " 8.976647291534631,\n",
       " 8.996466625106427,\n",
       " 8.988934048694542,\n",
       " 9.01354806968408,\n",
       " 8.993174606592465,\n",
       " 8.989982880055134,\n",
       " 8.978800296860456,\n",
       " 8.981456302587684,\n",
       " 8.985467235093276,\n",
       " 8.991963968528026,\n",
       " 8.991198535267388,\n",
       " 9.008781218867586,\n",
       " 8.990579693970446,\n",
       " 8.992715331742621,\n",
       " 8.99182025175686,\n",
       " 8.994862691761604,\n",
       " 8.987484245029222,\n",
       " 9.01010200496792,\n",
       " 8.975410623374836,\n",
       " 9.010583647692851,\n",
       " 8.997521483736445,\n",
       " 8.990546659828773,\n",
       " 9.003036565404837,\n",
       " 8.995722354767551,\n",
       " 9.001213061024051,\n",
       " 8.983626294621201,\n",
       " 9.009912465816937,\n",
       " 8.985708228184887,\n",
       " 8.98859102369433,\n",
       " 8.990392130975268,\n",
       " 9.00683394667406,\n",
       " 8.982691541737672,\n",
       " 8.978576865076095,\n",
       " 9.002467990075587,\n",
       " 8.991667026158144,\n",
       " 8.988627955124976,\n",
       " 8.997249631456626,\n",
       " 8.972978607051132,\n",
       " 9.000726692051234,\n",
       " 8.975984290588734,\n",
       " 9.001516551010369,\n",
       " 8.981662084658941,\n",
       " 9.00014232087505,\n",
       " 8.999740730576429,\n",
       " 8.986030516197824,\n",
       " 9.001148258761843,\n",
       " 8.995373096268922,\n",
       " 8.996288515261593,\n",
       " 8.997090840370465,\n",
       " 9.002299999620872,\n",
       " 8.991195489115801,\n",
       " 8.997807731385072,\n",
       " 8.998541201731955,\n",
       " 8.990289288012248,\n",
       " 8.995580749225248,\n",
       " 8.962131349692356,\n",
       " 9.009366629813684,\n",
       " 9.003997430320858,\n",
       " 8.997639363819314,\n",
       " 8.989501650327243,\n",
       " 9.000077851828987,\n",
       " 8.988222493489275,\n",
       " 8.992906340717962,\n",
       " 8.999643871565505,\n",
       " 8.999893257938306,\n",
       " 8.996528321458388,\n",
       " 8.986066554636919,\n",
       " 8.984479698561882,\n",
       " 9.020001573079009,\n",
       " 8.984184977158096,\n",
       " 9.003699019089225,\n",
       " 9.00118697051546,\n",
       " 8.990259654531183,\n",
       " 8.969481581942363,\n",
       " 8.993970730276995,\n",
       " 8.999391208015362,\n",
       " 8.989195398736062,\n",
       " 9.002686647019646,\n",
       " 8.985471781410604,\n",
       " 9.001588105847361,\n",
       " 8.993544307482027,\n",
       " 8.986684668048715,\n",
       " 9.004963032728018,\n",
       " 8.981531380451926,\n",
       " 8.991392277854974,\n",
       " 9.003846825478306,\n",
       " 8.989488863667777,\n",
       " 8.990021839853405,\n",
       " 8.967012376748315,\n",
       " 9.00266136271393,\n",
       " 8.99898833128833,\n",
       " 8.97704658905665,\n",
       " 8.994550247910103,\n",
       " 8.98821880662626,\n",
       " 8.988555959991398,\n",
       " 9.00150224050502,\n",
       " 8.984941778949988,\n",
       " 9.006752740928677,\n",
       " 8.984387031705804,\n",
       " 8.979586250098176,\n",
       " 9.003919822320304,\n",
       " 8.988519274295147,\n",
       " 8.983344867286448,\n",
       " 8.998817795314839,\n",
       " 8.979064184180833,\n",
       " 9.000461324317818,\n",
       " 8.983329871751232,\n",
       " 9.006627755494696,\n",
       " 8.998860385836865,\n",
       " 8.969865374940927,\n",
       " 8.995024766955881,\n",
       " 8.996241438142397,\n",
       " 8.998309248370102,\n",
       " 8.99913895592209,\n",
       " 8.986216150975043,\n",
       " 9.001057801282068,\n",
       " 8.979740411813253]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss is not decreasing so we have a fully trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_configuration/v3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[ 0.7664,  0.9821, 21.3793,  0.5757,  0.5077,  0.3798]])), ('0.bias', tensor([0.0416]))])\n"
     ]
    }
   ],
   "source": [
    "# checkpoint = torch.load(\"model_checkpoint.pth\")\n",
    "# model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "# print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_inputs = torch.tensor([[.20], [.34], [.57]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data prep, model config, and model training we did is the\n",
    "# general structure you'll use over and over again for training PyTorch\n",
    "# models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c2e14bd43ff3ec6e4c4093815f171ce19e8dcbd3f3f9ceb9a14c80d8da698828"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
